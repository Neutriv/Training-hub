{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Workshop2: 1. BiGAN/ALI.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "_MWwbcLRS4AP"
      },
      "cell_type": "markdown",
      "source": [
        "# BiGAN / ALI\n",
        "![Bigan_architecture](https://i.imgur.com/FglUXHR.png)"
      ]
    },
    {
      "metadata": {
        "id": "TmWyvUD419jW"
      },
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision matplotlib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qVaWeGco2Zxu"
      },
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "from itertools import chain\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wX1Fobor2Z0n"
      },
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JAUm4ZG-E10v"
      },
      "cell_type": "markdown",
      "source": [
        "In thic cell we initialize the data loaders for the MNIST dataset that will be used for provide data to training loop later.\n",
        "\n",
        "Here, we also specify size of the minibatch."
      ]
    },
    {
      "metadata": {
        "id": "NChsvnIR2Z2_"
      },
      "cell_type": "code",
      "source": [
        "batch_size = 100\n",
        "\n",
        "train_data = datasets.MNIST('data/mnist', train=True, download=True,\n",
        "                           transform=transforms.ToTensor())\n",
        "\n",
        "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True, \n",
        "                              num_workers=4, pin_memory=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qUYqvtk2BddE"
      },
      "cell_type": "markdown",
      "source": [
        "In this cell we specify dimensions of vectors for:\n",
        "* `X_len` - linearized images (MNIST containes images of size $28 \\times 28 = 784$)\n",
        "* `z_len` - encoding vector. Here, 64 is used, but you can try smaller or larger vectors\n"
      ]
    },
    {
      "metadata": {
        "id": "qtRQzMqhDv7h"
      },
      "cell_type": "code",
      "source": [
        "X_len = 28 * 28\n",
        "z_len = 64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_xXHEM6bLlC6"
      },
      "cell_type": "markdown",
      "source": [
        "Model of an Encoder $E: X \\rightarrow z$ - takes linearized images $X \\in [0, 1]^{784}$ as an input and returns encoding $z \\in \\mathbb{R}^{h}$, where $h$ - length of a vector specified by `z_len` in previous cell.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "q0KCYcvk2Z5X"
      },
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self, X_dim, z_dim):\n",
        "    super().__init__()\n",
        "    \n",
        "    self.model = nn.Sequential(\n",
        "      torch.nn.Linear(X_dim, 128),\n",
        "      torch.nn.ReLU(),\n",
        "      torch.nn.Linear(128, z_dim)\n",
        "    )\n",
        "  \n",
        "  def forward(self, X):\n",
        "    z = self.model(X)\n",
        "    return z"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OEEDTQO0KzC_"
      },
      "cell_type": "markdown",
      "source": [
        "Model of a Generator $G: z \\rightarrow X$ - takes feature vecor $z$ sampled from unit gaussian distribution $z \\sim \\mathcal{N}(0, I)  \\in \\mathbb{R}^{h}$ and produces a linearized image $X \\in [0, 1]^{784}$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "FRYcJMRI2Z7c"
      },
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "  def __init__(self, X_dim, z_dim):\n",
        "    super().__init__()\n",
        "    \n",
        "    self.model = nn.Sequential(\n",
        "      torch.nn.Linear(z_dim, 128),\n",
        "      torch.nn.ReLU(),\n",
        "      torch.nn.Linear(128, X_dim),\n",
        "      torch.nn.Sigmoid()\n",
        "    )\n",
        "  \n",
        "  def forward(self, z):\n",
        "    X = self.model(z)\n",
        "    return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ywI1dUgD7G84"
      },
      "cell_type": "markdown",
      "source": [
        "Model of a Discriminator $D: (X, z) \\rightarrow [0, 1]$ - takes linearized image $X$ (taken from the dataset or generated by a Generator) and feature vecor $z$ (sampled or infered by an Encoder) and returns the probability, that input is a pair of type $(X, E(X))$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "89rY52Gh2Z-p"
      },
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "  def __init__(self, x_dim, z_dim):\n",
        "    super().__init__()\n",
        "    \n",
        "    self.model = nn.Sequential(\n",
        "      torch.nn.Linear(x_dim + z_dim, 128),\n",
        "      torch.nn.ReLU(),\n",
        "      torch.nn.Linear(128, 1),\n",
        "      torch.nn.Sigmoid()\n",
        "    )\n",
        "  \n",
        "  def forward(self, X, z):\n",
        "    Xz = torch.cat([X, z], dim=1)\n",
        "    p = self.model(Xz)\n",
        "    return p"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GbwFTDts2aDE"
      },
      "cell_type": "code",
      "source": [
        "E = Encoder(X_dim=X_len, z_dim=z_len).to(device)\n",
        "G = Generator(X_dim=X_len, z_dim=z_len).to(device)\n",
        "D = Discriminator(x_dim=X_len, z_dim=z_len).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H2L-B3J68Ldr"
      },
      "cell_type": "markdown",
      "source": [
        "Weight initialization - we use the weight initialization from \"Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification\" by He et al."
      ]
    },
    {
      "metadata": {
        "id": "RFzExAxU2aFd"
      },
      "cell_type": "code",
      "source": [
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname in ('Conv1d', 'Linear'):\n",
        "        torch.nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
        "        if m.bias is not None:\n",
        "            torch.nn.init.constant_(m.bias, 0)\n",
        "\n",
        "E = E.apply(weights_init)\n",
        "G = G.apply(weights_init)\n",
        "D = D.apply(weights_init)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Mz7iHisF8kgu"
      },
      "cell_type": "markdown",
      "source": [
        "Define optimizers that will calculate optimization steps for our weights. Note, that Encoder and Generator share the same optimizer. Here we use Adam from \"Adam: A Method for Stochastic Optimization\" by Kingma et al."
      ]
    },
    {
      "metadata": {
        "id": "4u7vymwq2aIM"
      },
      "cell_type": "code",
      "source": [
        "learning_rate = 3e-4\n",
        "betas = (0.9, 0.999)\n",
        "\n",
        "EG_optimizer = optim.Adam(chain(E.parameters(), G.parameters()), \n",
        "                          lr=learning_rate, betas=betas)\n",
        "D_optimizer = optim.Adam(D.parameters(), lr=learning_rate, betas=betas)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lzuMEhGB9IDp"
      },
      "cell_type": "markdown",
      "source": [
        "Define the losses for BiGAN here. Remember to add epsilon ($10^{-6}$ is enough), where might be numerical instability (e.g. low values passed to logarithm function).\n",
        "\n",
        "Losses for BiGAN are:\n",
        "\n",
        "$L_D = \\log(D(X, E(X))) + \\log(1 - D(G(z), z))$\n",
        "\n",
        "$L_{EG} = \\log(D(G(z), z)) + \\log(1 - D(X, E(X)))$\n",
        "\n",
        "where $\\log$ means natural logarithm"
      ]
    },
    {
      "metadata": {
        "id": "l0JIAjOV2aKI"
      },
      "cell_type": "code",
      "source": [
        "def loss_fn_eg(p_enc, p_gen):\n",
        "  eps = 1e-8\n",
        "  return None\n",
        "\n",
        "def loss_fn_d(p_enc, p_gen):\n",
        "  eps = 1e-8\n",
        "  return None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tkqL8OGJAwTc"
      },
      "cell_type": "markdown",
      "source": [
        "Training procedure for BiGAN - fill the training steps, that are currently `None`"
      ]
    },
    {
      "metadata": {
        "id": "PyiQVp0Q2aPZ"
      },
      "cell_type": "code",
      "source": [
        "max_epochs = 300\n",
        "for epoch_n in range(1, max_epochs+1):\n",
        "  \n",
        "  D.train()\n",
        "  E.train()\n",
        "  G.train()\n",
        "\n",
        "  d_losses = 0.0\n",
        "  eg_losses = 0.0\n",
        "  \n",
        "  start = datetime.now()\n",
        "  for i, (X, y) in enumerate(train_dataloader, 1):\n",
        "    X = X.to(device)\n",
        "    y = y.to(device)\n",
        "    \n",
        "    X = X.view(X.size(0), -1)\n",
        "   \n",
        "    z_ = None\n",
        "    z = None\n",
        "    X_ = None\n",
        "  \n",
        "    p_enc = None\n",
        "    p_gen = None\n",
        "    \n",
        "    D_optimizer.zero_grad()\n",
        "    D.zero_grad()\n",
        "    loss_d  = -torch.mean(loss_fn_d(p_enc, p_gen))\n",
        "    loss_d.backward(retain_graph=True)\n",
        "    d_losses += loss_d.item()\n",
        "    D_optimizer.step()\n",
        "    \n",
        "    \n",
        "    EG_optimizer.zero_grad()\n",
        "    E.zero_grad()\n",
        "    G.zero_grad()\n",
        "    loss_eg = -torch.mean(loss_fn_eg(p_enc, p_gen))\n",
        "    loss_eg.backward()\n",
        "    eg_losses += loss_eg.item()\n",
        "    EG_optimizer.step()\n",
        "   \n",
        "  print(f'Epoch {epoch_n:03d}: Z mean/std: {z_.mean():.4f}/{z_.std():.4f} '\n",
        "        f'Loss_EG: {eg_losses / i:.4f} Loss_D: {d_losses / i:.4f} '\n",
        "        f'Time: {datetime.now() - start}')\n",
        "  \n",
        "  # Visualize learning\n",
        "  D.eval()\n",
        "  E.eval()\n",
        "  G.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    X = X[:10] # take 10 elements from the last minibatch\n",
        "    reconstructions = G(E(X)).view(10, 28, 28).cpu().numpy()\n",
        "    reals = X.view(10, 28, 28).cpu().numpy()\n",
        "\n",
        "    z = torch.randn(10, z_len).to(device)\n",
        "    samples = G(z).view(10, 28, 28).cpu().numpy()\n",
        "\n",
        "    fig, ax = plt.subplots(1, 10, figsize=(5, 1))\n",
        "    fig.suptitle(f'Real: {epoch_n}')\n",
        "    for i, real in enumerate(reals):\n",
        "      ax[i].imshow(real)\n",
        "      ax[i].axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    fig, ax = plt.subplots(1, 10, figsize=(5, 1))\n",
        "    fig.suptitle(f'Reconstructions: {epoch_n}')\n",
        "    for i, reconstruction in enumerate(reconstructions):\n",
        "      ax[i].imshow(reconstruction)\n",
        "      ax[i].axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    fig, ax = plt.subplots(1, 10, figsize=(5, 1))\n",
        "    fig.suptitle(f'Synthetic: {epoch_n}')\n",
        "    for i, sample in enumerate(samples):\n",
        "      ax[i].imshow(sample)\n",
        "      ax[i].axis('off')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}